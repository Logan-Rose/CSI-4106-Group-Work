{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 19:09:48.183620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-06 19:09:48.183640: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-40eefd98af7b1785\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-40eefd98af7b1785\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# load tensorboard extension\n",
    "%reload_ext tensorboard\n",
    "# specify the log directory where the tensorboard logs will be written\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the relevant datasets (15/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the model input with the required shape \n",
    "# (1)\n",
    "in_shape = keras.Input(shape=(256, 256, 1))\n",
    "\n",
    "# The shared layers\n",
    "# Include at least one Conv2D layer, MaxPooling2D layer and a Flatten layer\n",
    "# you can have as many layers as possible, but make sure not to overfit your model using the training data\n",
    "# TODO\n",
    "\n",
    "leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "reg = tf.keras.regularizers.l2(l2=0.0001)\n",
    "\n",
    "layer1 = tf.keras.layers.Conv2D(8, (3,3), name=\"layer1\")\n",
    "layer2 = tf.keras.layers.MaxPool2D(3,3, name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Flatten(name=\"layer3\")\n",
    "layer4 = tf.keras.layers.Normalization(name=\"layer4\")\n",
    "layer5 = tf.keras.layers.Dropout(.5, name=\"layer5\")\n",
    "layer6 = tf.keras.layers.Dense(units=64, activation = tf.nn.relu, name=\"layer6\")\n",
    "layer7 = tf.keras.layers.Dense(units=64, activation = tf.nn.relu, name=\"layer7\")\n",
    "layer8 = tf.keras.layers.Dense(units=128, activation = tf.nn.relu, name=\"layer8\")\n",
    "\n",
    "sharedLayers = layer8(layer7(layer6(layer5(layer4(layer3((layer2(layer1(in_shape)))))))))\n",
    "\n",
    "# Task specific layers\n",
    "# Include at least one Dense layer as a task specific layer before generating the output for age\n",
    "# TODO\n",
    "\n",
    "ageTaskLayer = tf.keras.layers.Dense(units=256, activation= tf.nn.relu, name=\"ageTask\")\n",
    "\n",
    "# Include the age output and make sure to include the following arguments\n",
    "# activation='linear', name='xxx'(any name)\n",
    "# make sure to name your output layers so that different metrics to be used can be linked accordingly\n",
    "# please note that the age prediction is a regression task\n",
    "\n",
    "ageLayer = tf.keras.layers.Dense(units=120, activation= tf.nn.softmax, name=\"age\")\n",
    "ageOutput = ageLayer(ageTaskLayer(sharedLayers))\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for ethnicity prediction\n",
    "\n",
    "ethTaskLayer = tf.keras.layers.Dense(units=256, activation= tf.nn.relu, name=\"ethTask\")\n",
    "\n",
    "# Include the ethnicity output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a multi-class classification task\n",
    "\n",
    "ethLayer = tf.keras.layers.Dense(units=5, activation= tf.nn.sigmoid, name=\"eth\")\n",
    "ethOutput = ethLayer(ethTaskLayer(sharedLayers))\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for gender prediction\n",
    "\n",
    "genTaskLayer = tf.keras.layers.Dense(units=256, activation= tf.nn.relu, name=\"genTask\")\n",
    "\n",
    "# Include the gender output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a binary classification task\n",
    "\n",
    "genLayer = tf.keras.layers.Dense(units=2, activation= tf.nn.softmax, name=\"gen\")\n",
    "genOutput = genLayer(genTaskLayer(sharedLayers))\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "# pelase make sure that the outputs can be included in a list and make sure to keep note of the order\n",
    "# (3)\n",
    "\n",
    "outputs = [ageOutput, ethOutput, genOutput]\n",
    "\n",
    "model = tf.keras.Model(inputs = in_shape, outputs = outputs, name = \"tmo\")\n",
    "\n",
    "# print the model summary\n",
    "# (0.5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "# (2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "\n",
    "losses = [\n",
    "#age\n",
    "tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#ethnicity\n",
    "tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#gender\n",
    "tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "]\n",
    "\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# loss_weights=[0.001, 0.5, 0.5]\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "# (2)\n",
    "\n",
    "metrics = [\n",
    "tf.keras.metrics.MeanAbsoluteError(), \n",
    "tf.keras.metrics.Accuracy(),\n",
    "tf.keras.metrics.Accuracy()\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=losses,\n",
    "              loss_weights=[0.001, 0.5, 0.5],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# (2)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# (2)\n",
    "\n",
    "\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# (2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=1,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)\n",
    "\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15026, 4)\n",
      "(4696, 4)\n",
      "(3757, 4)\n",
      "['age' 'ethnicity' 'gender' 'img_name']\n",
      "5\n",
      "Train Gender Distribution:\n",
      "0    0.52336\n",
      "1    0.47664\n",
      "Name: gender, dtype: float64\n",
      "\n",
      "Test Gender Distribution:\n",
      "0    0.522998\n",
      "1    0.477002\n",
      "Name: gender, dtype: float64\n",
      "\n",
      "Val Gender Distribution:\n",
      "0    0.523024\n",
      "1    0.476976\n",
      "Name: gender, dtype: float64\n",
      "\n",
      "Train Ethnicity Distribution:\n",
      "0    0.424065\n",
      "1    0.190936\n",
      "3    0.167976\n",
      "2    0.145481\n",
      "4    0.071543\n",
      "Name: ethnicity, dtype: float64\n",
      "\n",
      "Test Eethnicity Distribution:\n",
      "0    0.423978\n",
      "1    0.190801\n",
      "3    0.168228\n",
      "2    0.145443\n",
      "4    0.071550\n",
      "Name: ethnicity, dtype: float64\n",
      "\n",
      "Val Eethnicity Distribution:\n",
      "0    0.424009\n",
      "1    0.190844\n",
      "3    0.168219\n",
      "2    0.145595\n",
      "4    0.071334\n",
      "Name: ethnicity, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the datasets using the csv files train, val and test (3)\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "val = pd.read_csv('./data/val.csv')\n",
    "\n",
    "# print the shapes of the dataframes (3)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(val.shape)\n",
    "\n",
    "# print the column names from either one of the dataframes (1)\n",
    "print(train.columns.values)\n",
    "\n",
    "num_ethnecities = train['ethnicity'].nunique()\n",
    "print(num_ethnecities)\n",
    "\n",
    "# print the proportional distribution of gender in all three datasets(i.e., number of male and female) (3)\n",
    "print(f\"Train Gender Distribution:\\n{train['gender'].value_counts() / len(train)}\\n\")\n",
    "print(f\"Test Gender Distribution:\\n{test['gender'].value_counts() / len(test)}\\n\")\n",
    "print(f\"Val Gender Distribution:\\n{val['gender'].value_counts() / len(val)}\\n\")\n",
    "\n",
    "# print the proportional distribution of ethnicity in all three datasets (3)\n",
    "print(f\"Train Ethnicity Distribution:\\n{train['ethnicity'].value_counts() / len(train)}\\n\")\n",
    "print(f\"Test Eethnicity Distribution:\\n{test['ethnicity'].value_counts() / len(test)}\\n\")\n",
    "print(f\"Val Eethnicity Distribution:\\n{val['ethnicity'].value_counts() / len(val)}\\n\")\n",
    "\n",
    "# plot the age distribution from the training dataset where the x-axis plots the age and the y-axis \n",
    "# depicts the count of individuals within each age group. For example, individuals with age=1 are: (2)\n",
    "train['age'].hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ImageDataGenerators (22/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15026 validated image filenames.\n",
      "Found 3757 validated image filenames.\n",
      "Found 4696 validated image filenames.\n",
      "39\n",
      "4\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ImageDataGenerator is an iterator.\n",
    "\n",
    "# specify the batch size hyperparameter. You can experiment with different batch sizes\n",
    "batch_size =11\n",
    "\n",
    "# create the ImageDataGenerator with rescaling that will generate batched tensors representing images with real-time data augmentation\n",
    "# use at least two of the augmentation strategies. For example, fill_mode='nearest'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (3)\n",
    "train_img_gen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance to link the image folder and the dataframe.\n",
    "# also include the, batch size, image size and the seed.\n",
    "# make sure to include the following arguments\n",
    "# color_mode='grayscale', class_mode='multi_output'\n",
    "# please refer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# (5)\n",
    "train_generator = train_img_gen.flow_from_dataframe(\n",
    "  dataframe=train,\n",
    "  directory='./data/images/train/',\n",
    "  x_col='img_name',\n",
    "  y_col=['age','ethnicity','gender'],\n",
    "  class_mode='multi_output',\n",
    "  color_mode='grayscale',\n",
    "  batch_size=batch_size,\n",
    "  seed = SEED,\n",
    "  target_size=(48,48)\n",
    ")\n",
    "\n",
    "# similarly, create an ImageDataGenerator for the validation dataset and make sure not to use any of the augmentation strategies except rescaling the image\n",
    "# (2)\n",
    "val_img_gen = ImageDataGenerator(\n",
    "      rescale=1./255\n",
    ")\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the \"ImageDataGenerator\" instance with the same arguments as above\n",
    "# make sure to specify the following arguments:\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "val_generator = val_img_gen.flow_from_dataframe(\n",
    "  dataframe=val,\n",
    "  directory='./data/images/val/',\n",
    "  x_col='img_name',\n",
    "  y_col=['age','ethnicity','gender'],\n",
    "  class_mode='multi_output',\n",
    "  color_mode='grayscale',\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  seed = SEED,\n",
    "  target_size=(48,48)\n",
    ")\n",
    "\n",
    "\n",
    "# use the method \"flow_from_dataframe\" from the val_img_gen instance to link the test dataframe and the test data folder\n",
    "# In addition, make sure to specify the following arguments\n",
    "# class_mode='multi_output', color_mode='grayscale', shuffle=False\n",
    "# (5)\n",
    "test_img_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_img_gen.flow_from_dataframe(\n",
    "  dataframe=test,\n",
    "  directory='./data/images/test/',\n",
    "  x_col='img_name',\n",
    "  y_col=['age','ethnicity','gender'],\n",
    "  class_mode='multi_output',\n",
    "  color_mode='grayscale',\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False,\n",
    "  target_size=(48,48)\n",
    ")\n",
    "\n",
    "\n",
    "# enumerate through the validation data generator created above and plot first grayscale image \n",
    "# (2)\n",
    "tmpx = enumerate(val_generator)\n",
    "for i, element in tmpx:\n",
    "    if i == 8:\n",
    "      print(element[1][0][i])\n",
    "      print(element[1][1][i])\n",
    "      print(element[1][2][i])\n",
    "      plt.imshow(element[0][i], cmap = 'gray')\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(val_generator.image_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model (44/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tmo\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " layer1 (Conv2D)                (None, 47, 47, 4)    20          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " layer2 (MaxPooling2D)          (None, 23, 23, 4)    0           ['layer1[0][0]']                 \n",
      "                                                                                                  \n",
      " layer3 (Flatten)               (None, 2116)         0           ['layer2[0][0]']                 \n",
      "                                                                                                  \n",
      " layer4 (Dense)                 (None, 64)           135488      ['layer3[0][0]']                 \n",
      "                                                                                                  \n",
      " layer5 (Dense)                 (None, 128)          8320        ['layer4[0][0]']                 \n",
      "                                                                                                  \n",
      " layer6 (Dense)                 (None, 256)          33024       ['layer5[0][0]']                 \n",
      "                                                                                                  \n",
      " gender_task1 (Dense)           (None, 128)          32896       ['layer6[0][0]']                 \n",
      "                                                                                                  \n",
      " age_task (Dense)               (None, 128)          32896       ['layer6[0][0]']                 \n",
      "                                                                                                  \n",
      " ethnicity_task (Dense)         (None, 128)          32896       ['layer6[0][0]']                 \n",
      "                                                                                                  \n",
      " gender_task2 (Dense)           (None, 64)           8256        ['gender_task1[0][0]']           \n",
      "                                                                                                  \n",
      " age (Dense)                    (None, 1)            129         ['age_task[0][0]']               \n",
      "                                                                                                  \n",
      " ethnicity (Dense)              (None, 5)            645         ['ethnicity_task[0][0]']         \n",
      "                                                                                                  \n",
      " gender (Dense)                 (None, 2)            130         ['gender_task2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 284,700\n",
      "Trainable params: 284,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# specify the model input with the required shape \n",
    "# (1)\n",
    "in_shape = keras.Input(shape=(256, 256, 1))\n",
    "\n",
    "# The shared layers\n",
    "# Include at least one Conv2D layer, MaxPooling2D layer and a Flatten layer\n",
    "# you can have as many layers as possible, but make sure not to overfit your model using the training data\n",
    "# TODO\n",
    "\n",
    "leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "reg = tf.keras.regularizers.l2(l2=0.0001)\n",
    "\n",
    "layer1 = tf.keras.layers.Conv2D(8, (3,3), name=\"layer1\")\n",
    "layer2 = tf.keras.layers.MaxPool2D(3,3, name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Flatten(name=\"layer3\")\n",
    "layer4 = tf.keras.layers.Normalization(name=\"layer4\")\n",
    "layer5 = tf.keras.layers.Dropout(.5, name=\"layer5\")\n",
    "layer6 = tf.keras.layers.Dense(units=64, activation = tf.nn.relu, name=\"layer6\")\n",
    "layer7 = tf.keras.layers.Dense(units=64, activation = tf.nn.relu, name=\"layer7\")\n",
    "layer8 = tf.keras.layers.Dense(units=128, activation = tf.nn.relu, name=\"layer8\")\n",
    "\n",
    "sharedLayers = layer8(layer7(layer6(layer5(layer4(layer3((layer2(layer1(in_shape)))))))))\n",
    "\n",
    "# Task specific layers\n",
    "# Include at least one Dense layer as a task specific layer before generating the output for age\n",
    "# TODO\n",
    "\n",
    "ageTaskLayer = tf.keras.layers.Dense(units=256, activation= tf.nn.relu, name=\"ageTask\")\n",
    "\n",
    "# Include the age output and make sure to include the following arguments\n",
    "# activation='linear', name='xxx'(any name)\n",
    "# make sure to name your output layers so that different metrics to be used can be linked accordingly\n",
    "# please note that the age prediction is a regression task\n",
    "\n",
    "ageLayer = tf.keras.layers.Dense(units=120, activation= tf.nn.softmax, name=\"age\")\n",
    "ageOutput = ageLayer(ageTaskLayer(sharedLayers))\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for ethnicity prediction\n",
    "\n",
    "ethTaskLayer = tf.keras.layers.Dense(units=256, activation= tf.nn.relu, name=\"ethTask\")\n",
    "\n",
    "# Include the ethnicity output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a multi-class classification task\n",
    "\n",
    "ethLayer = tf.keras.layers.Dense(units=5, activation= tf.nn.sigmoid, name=\"eth\")\n",
    "ethOutput = ethLayer(ethTaskLayer(sharedLayers))\n",
    "\n",
    "# Similar to above, specify one or more Dense layers as task specific layers for gender prediction\n",
    "\n",
    "genTaskLayer = tf.keras.layers.Dense(units=256, activation= tf.nn.relu, name=\"genTask\")\n",
    "tf.keras.optimizers.Adam()\n",
    "# Include the gender output that uses the task specific output from the layer above\n",
    "# please note that the ethnicity prediction is a binary classification task\n",
    "\n",
    "genLayer = tf.keras.layers.Dense(units=2, activation= tf.nn.softmax, name=\"gen\")\n",
    "genOutput = genLayer(genTaskLayer(sharedLayers))\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "# pelase make sure that the outputs can be included in a list and make sure to keep note of the order\n",
    "# (3)\n",
    "\n",
    "outputs = [ageOutput, ethOutput, genOutput]\n",
    "\n",
    "model = tf.keras.Model(inputs = in_shape, outputs = outputs, name = \"tmo\")\n",
    "\n",
    "# print the model summary\n",
    "# (0.5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "# (2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "\n",
    "losses = [\n",
    "#age\n",
    "tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#ethnicity\n",
    "tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#gender\n",
    "tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "]\n",
    "\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# loss_weights=[0.001, 0.5, 0.5]\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "# (2)\n",
    "\n",
    "metrics = [\n",
    "tf.keras.metrics.MeanAbsoluteError(), \n",
    "tf.keras.metrics.Accuracy(),\n",
    "tf.keras.metrics.Accuracy()\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=losses,\n",
    "              loss_weights=[0.001, 0.5, 0.5],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# (2)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# (2)\n",
    "\n",
    "\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# (2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=1,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)\n",
    "\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4491 - age_loss: 0.0000e+00 - ethnicity_loss: 10.2375 - gender_loss: 0.6608 - age_accuracy: 0.0000e+00 - ethnicity_sparse_categorical_accuracy: 0.0786 - gender_binary_accuracy: 0.4776"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 0.2500332756555304 to EagerTensor of dtype int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [early_stop, checkpoints, tensorboard, reduce_lr]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# fit the model with training and validation generators\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# In addition please specify the following arguments\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# steps_per_epoch=len(df_train)/batch_size\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# validation_steps=len(df_val)/batch_size\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# (5)\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/csi4106/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 0.2500332756555304 to EagerTensor of dtype int64"
     ]
    }
   ],
   "source": [
    "# Instantiate the optimizer with the learning rate. You can start with the learning rate 1e-3(0.001).\n",
    "# Both the optimizer and the learning rate are hyperparameters that you can finetune\n",
    "# For example, you can start with the \"RMSprop\" optimizer\n",
    "# TODO\n",
    "# (2)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001)\n",
    "# optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
    "# specify the losses to be used for each task: age, ethnicity and gender prediction \n",
    "# (0.5)\n",
    "losses = {'age': 'mean_squared_error', 'ethnicity': ['categorical_crossentropy'],'gender':['binary_crossentropy']}\n",
    "\n",
    "# compile the model with the optimizer, loss, loss_weights and the metrics for each task\n",
    "# apply the following weights to the losses to balance the contribution of each loss to the total loss\n",
    "# loss_weights=[0.001, 0.5, 0.5]\n",
    "# please remember to use the relevant metric for each task by assigning it to the correct output\n",
    "# TODO\n",
    "# (2)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              loss_weights=[0.001, 0.5, 0.5],\n",
    "              metrics={'age': 'accuracy', 'ethnicity': ['sparse_categorical_accuracy'],'gender':['binary_accuracy']}\n",
    "              )\n",
    "\n",
    "check_dir, tboard_dir = make_directories()\n",
    "\n",
    "# Define the callbacks\n",
    "# EarlyStopping: monitor the validation loss while waiting for 3 epochs before stopping\n",
    "# can restore the best weights\n",
    "# TODO\n",
    "# (2)\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "# TODO\n",
    "# (2)\n",
    "checkpoints = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=check_dir,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "# TODO\n",
    "# (2)\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=tboard_dir\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "# TODO\n",
    "# (2)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, checkpoints, tensorboard, reduce_lr]\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)\n",
    "\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        epochs=15,\n",
    "        validation_data=val_generator,\n",
    "        batch_size=batch_size, \n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=len(train)/batch_size,\n",
    "        validation_steps=len(val)/batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions on test data (14/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 43ms/step - loss: 5.4511 - age_loss: 0.0000e+00 - ethnicity_loss: 10.2410 - gender_loss: 0.6613 - age_accuracy: 0.0000e+00 - ethnicity_sparse_categorical_accuracy: 0.3778 - gender_binary_accuracy: 0.5230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 5.4511308670043945,\n",
       " 'age_loss': 0.0,\n",
       " 'ethnicity_loss': 10.240997314453125,\n",
       " 'gender_loss': 0.6612650752067566,\n",
       " 'age_accuracy': 0.0,\n",
       " 'ethnicity_sparse_categorical_accuracy': 0.37776830792427063,\n",
       " 'gender_binary_accuracy': 0.5229982733726501}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the trained model using the test generator\n",
    "# print only the test accuracy for ethnicity and gender predictions (4)\n",
    "result = model.evaluate(test_generator)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.01414664],\n",
      "       [0.02321187],\n",
      "       [0.0171011 ],\n",
      "       ...,\n",
      "       [0.02042973],\n",
      "       [0.03173344],\n",
      "       [0.02266643]], dtype=float32), array([[0.07431011, 0.04576685, 0.04780821, 0.03810893, 0.05392777],\n",
      "       [0.07265443, 0.02199829, 0.05997241, 0.02930011, 0.06242132],\n",
      "       [0.04812334, 0.04250259, 0.04807137, 0.03862368, 0.04535403],\n",
      "       ...,\n",
      "       [0.04073707, 0.02097819, 0.02908952, 0.02097313, 0.03325227],\n",
      "       [0.07380683, 0.04240367, 0.06600414, 0.04362871, 0.05748645],\n",
      "       [0.0645574 , 0.03532101, 0.04906441, 0.02966733, 0.05079977]],\n",
      "      dtype=float32), array([[0.49293727, 0.49182233],\n",
      "       [0.4947991 , 0.4934057 ],\n",
      "       [0.4942014 , 0.4945852 ],\n",
      "       ...,\n",
      "       [0.4953664 , 0.49645782],\n",
      "       [0.49137017, 0.49335498],\n",
      "       [0.49334997, 0.49361444]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate predictions using the test generator (2)\n",
    "pred = model.predict(test_generator)\n",
    "print(pred)\n",
    "\n",
    "# extract the ethnicity predictions (2)\n",
    "# print the classification report for predicting ethnicity (2)\n",
    "\n",
    "\n",
    "# extract the gender predictions where probabilities above 0.5 are considered class 1 and if not, class 0\n",
    "(2)\n",
    "# print the classification report for predicting gender\n",
    "(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01414664]\n",
      "[0.07431011 0.04576685 0.04780821 0.03810893 0.05392777]\n",
      "[0.49293727 0.49182233]\n",
      "([array([30,  1, 27, 28, 28, 38,  2, 42, 27, 23, 28, 66, 38, 72, 78, 26, 40,\n",
      "       80, 36, 29, 65,  1, 79, 39, 28, 15, 28, 24,  1, 32, 57, 54, 29, 25,\n",
      "        4, 46,  1, 15, 49,  4, 56, 32, 25, 25, 21, 16, 46, 44, 65, 63, 32,\n",
      "       69, 16, 65, 25, 54, 51, 22, 21, 30, 53, 20, 90,  1, 26,  1, 19, 16,\n",
      "       99,  3, 16, 65, 73,  1,  2, 34, 25, 28,  7, 27, 25,  1, 49, 52, 24,\n",
      "       36,  8, 32, 60,  1, 22, 86, 22, 32, 47,  4, 16, 28, 36, 41]), array([2, 2, 1, 3, 2, 0, 4, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 4, 1, 3, 3,\n",
      "       1, 0, 0, 0, 1, 2, 3, 0, 1, 0, 0, 3, 2, 3, 2, 3, 1, 2, 0, 1, 1, 1,\n",
      "       1, 0, 3, 3, 2, 0, 4, 0, 0, 0, 3, 3, 1, 4, 1, 4, 0, 4, 0, 2, 0, 0,\n",
      "       0, 0, 0, 2, 0, 0, 0, 3, 0, 3, 0, 3, 2, 3, 0, 0, 0, 0, 4, 0, 0, 2,\n",
      "       3, 0, 1, 0, 1, 0, 0, 2, 0, 1, 3, 3]), array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1])],)\n"
     ]
    }
   ],
   "source": [
    "# extract the ethnicity predictions (2)\n",
    "\n",
    "print(pred[0][0])\n",
    "print(pred[1][0])\n",
    "print(pred[2][0])\n",
    "\n",
    "print(test_generator[0][1:])\n",
    "# print the classification report for predicting ethnicity (2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present prediction results on test data(5/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present your findings for 5 different runs by fine-tuning the hyperparameters. The results table must contain the following fields\n",
    "- A minimum of 5 hyperparameters that you have fine-tuned\n",
    "- Mean absolute error for age\n",
    "- Accuracy for ethnicity prediction\n",
    "- Accuracy for gender prediction\n",
    "Please use a table format similar to the one mentioned below when presenting the results.\n",
    "\n",
    "| Hyperparameters | Age(MAE) | Ethnicity(Accuracy)| Gender(Accuracy) |\n",
    "|-----------------|----------|--------------------|------------------|\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n",
    "|                 |          |                    |                  |\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
